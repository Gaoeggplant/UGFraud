{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users = 38063\n",
      "number of products = 201\n",
      "number of users = 38063\n",
      "number of users = 38063\n",
      "number of products = 201\n",
      "[ 62.66578014   0.           0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.           0.           0.\n",
      "   0.        ]\n",
      "number of positive 7739\n",
      "number of negative 30324\n",
      "number of all users 38063\n",
      "AUC = 0.497467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jean/Applications/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0, '../../Utils')\n",
    "from iohelper import *\n",
    "from eval_helper import *\n",
    "sys.path.insert(0, '../../SpEagle/featureExtractorPy')\n",
    "from featureExtraction import *\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from SVD import *\n",
    "\n",
    "dataset_name = 'YelpChi'\n",
    "prefix = '../Yelp_Dataset/' + dataset_name + '/'\n",
    "evasive_prefix = '../../Attack/' + dataset_name + '2' +'/'\n",
    "\n",
    "metadata_filename = prefix + 'metadata.gz'\n",
    "\n",
    "evasion_filename = evasive_prefix + 'priors/'+ 'Weak/' + 'new_spammer_new_business.pickle'\n",
    "\n",
    "\n",
    "# read the graph and node priors\n",
    "user_product_graph, product_user_graph = read_graph_data(metadata_filename)\n",
    "\n",
    "feature_suspicious_filename = 'feature_configuration.txt'\n",
    "review_feature_list = ['RD', 'EXT', 'EXT', 'DEV', 'ETF', 'ISR']\n",
    "user_feature_list = ['MNR', 'PR', 'NR', 'avgRD', 'BST', 'ERD', 'ETG']\n",
    "product_feature_list = ['MNR', 'PR', 'NR', 'avgRD', 'ERD', 'ETG']\n",
    "\n",
    "# read the graph and node priors\n",
    "feature_config = load_feature_config('../../SpEagle/', feature_suspicious_filename)\n",
    "numerical_eps = 1e-5\n",
    "user_review_potential = np.log(np.array([[1-numerical_eps, numerical_eps], [numerical_eps, 1 - numerical_eps]]))\n",
    "eps = 0.1\n",
    "review_product_potential = np.log(np.array([[1 - eps, eps], [eps, 1 - eps]]))\n",
    "    \n",
    "potentials = {'u_r': user_review_potential, 'r_u': user_review_potential,\n",
    "            'r_p': review_product_potential, 'p_r': review_product_potential}\n",
    "\n",
    "text_features = []\n",
    "new_user_graph = {}\n",
    "new_product_graph = {}\n",
    "\n",
    "## add edges from evasions and camouflage\n",
    "\n",
    "with open(evasion_filename, 'rb') as f:\n",
    "    evasions = pickle.load(f)\n",
    "    spammer_ids = evasions[0]   \n",
    "    target_ids = evasions[1]\n",
    "    new_edges = evasions[2]\n",
    "\n",
    "for added_edge in new_edges:\n",
    "    added_account = added_edge[0]\n",
    "    target = added_edge[1]\n",
    "    if added_account not in new_user_graph.keys():\n",
    "        # a tuple of (product_id, rating, label, posting_date)\n",
    "        new_user_graph[added_account] = [(target, 5, -1, '2012-06-01')]\n",
    "    else:\n",
    "        new_user_graph[added_account].append((target, 5, -1, '2012-06-01'))\n",
    "    if target not in new_product_graph.keys():\n",
    "        # a tuple of (user_id, rating, label, posting_date)\n",
    "        new_product_graph[target] = [(added_account, 5, -1, '2012-06-01')]\n",
    "    else:\n",
    "        new_product_graph[target].append((added_account, 5, -1, '2012-06-01'))\n",
    "\n",
    "feature_extractor = FeatureExtractor()\n",
    "UserFeatures, ProdFeatures, ReviewFeatures = feature_extractor.construct_all_features(user_product_graph, prod_user_graph)\n",
    "UserFeatures, ProdFeatures, ReviewFeatures = feature_extractor.update_all_features(user_product_graph, new_user_graph,\n",
    "                                                                                   prod_user_graph,\n",
    "                                                                                   new_product_graph, UserFeatures,\n",
    "                                                                                   ProdFeatures, ReviewFeatures)\n",
    "new_upriors = feature_extractor.calculateNodePriors(user_feature_list, UserFeatures, feature_config)\n",
    "new_ppriors = feature_extractor.calculateNodePriors(product_feature_list, ProdFeatures, feature_config)\n",
    "new_rpriors = feature_extractor.calculateNodePriors(review_feature_list, ReviewFeatures, feature_config)\n",
    "\n",
    "user_priors = new_upriors\n",
    "review_priors = new_rpriors\n",
    "prod_priors = new_ppriors\n",
    "\n",
    "#create ground truth\n",
    "evasive_spams = {}\n",
    "for added_edge in new_edges:\n",
    "    added_account = added_edge[0]\n",
    "    target = added_edge[1]\n",
    "    if target not in evasive_spams.keys():\n",
    "        evasive_spams[target] = [(added_account, 5, 1, '2012-06-01')]\n",
    "    evasive_spams[target].append((added_account, 5, 1, '2012-06-01'))\n",
    "\n",
    "user_ground_truth, review_ground_truth = create_evasion_ground_truth(user_product_graph, evasive_spams)\n",
    "\n",
    "# add new edges into the original graph\n",
    "for e in new_edges:\n",
    "    u_id = str(e[0])\n",
    "    p_id = str(e[1])\n",
    "    user_product_graph[u_id].append((p_id, 5, 1, '2012-06-01'))\n",
    "    prod_user_graph[p_id].append((u_id, 5, 1, '2012-06-01')) \n",
    "\n",
    "print('number of users = %d' % len(user_product_graph))\n",
    "print('number of users = %d' % len(user_priors))\n",
    "print('number of products = %d' % len(prod_priors))  \n",
    "\n",
    "percent = 0.9 \n",
    "    \n",
    "#run SVD on user-product graph\n",
    "model = SVD(user_product_graph, user_priors, prod_priors)\n",
    "svd_output = model.run(percent)\n",
    "\n",
    "#     print(len(svd_output[1,:]))\n",
    "#     print(svd_output)\n",
    "\n",
    "#evaluate the SVD based detection with SVM\n",
    "#result contains the [userid, pred_probas], prediction is the binary pred result, y_ture is the true label vector\n",
    "result, predictions, y_true = model.evaluate_SVD(svd_output, user_product_graph, user_priors, prod_priors, spammer_ids, percent)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
